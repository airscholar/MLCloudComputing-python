{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1795e9e2-fda9-442b-8a76-8cd77c3a9138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install paramiko\n",
    "# !pip install scp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09e8788d-0182-49f9-9128-a6dfbca0b8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import numpy as np\n",
    "import time\n",
    "import datetime\n",
    "import sys\n",
    "from MLBD import MLBDApp\n",
    "np.set_printoptions(threshold=sys.maxsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "INSTANCE_SIZE = 1\n",
    "client = boto3.client('ec2', region_name='us-east-1')\n",
    "# Create SQS client\n",
    "sqs = boto3.resource('sqs')\n",
    "mlbd = MLBDApp()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "# def send_mul(matrix_a = np.random.randint(10, size=(500, 500)),matrix_b = np.random.randint(10, size=(500, 500)),size_x=None, size_y=None):\n",
    "#     \"\"\"\n",
    "#     Send the work to the workers\n",
    "#     :param matrix_a: the first matrix\n",
    "#     :param matrix_b: the second matrix\n",
    "#     :param size_x: the size of the matrix\n",
    "#     :param size_y: the size of the matrix\n",
    "#     :return: the proof of work\n",
    "#     \"\"\"\n",
    "#     # if size_x!=None: #if the size is given\n",
    "#     #     matrix_a=np.random.randint(10, size=(size_x, size_y))\n",
    "#     #     matrix_b=np.random.randint(10, size=(size_x, size_y))\n",
    "#     #\n",
    "#     # if matrix_b.shape!=matrix_a.shape: #if the matrix are not the same size\n",
    "#     #     print(\"Shape of matrix are not the same\")\n",
    "#     #     return\n",
    "#     #\n",
    "#     # if len(matrix_b)<100: #if the matrix are too small\n",
    "#     #     print(\"Maybe its not worth it to parallelize this work\")\n",
    "#     #     return\n",
    "#\n",
    "#     lenght=len(matrix_b)\n",
    "#     # max_el=43000\n",
    "#     max_el=100\n",
    "#     split=max_el//lenght\n",
    "#\n",
    "#     if split>lenght:\n",
    "#         split=lenght\n",
    "#\n",
    "#     rest=lenght%split\n",
    "#     print(\"SENDING\", lenght, split, rest)\n",
    "#     nbr_msg=(len(matrix_a)//split)**2\n",
    "#     msg=0\n",
    "#\n",
    "#     id=0\n",
    "#     messages=[]\n",
    "#     # Send the work to the queue\n",
    "#     for i in range(int(len(matrix_a)/split)):\n",
    "#\n",
    "#         for j in range(int(len(matrix_b)/split)):\n",
    "#\n",
    "#             messages.append({\n",
    "#                 'Id':str(i),\n",
    "#                 'MessageBody':str({\n",
    "#                     'A': matrix_a[i*split:i*split+split].tolist(),\n",
    "#                     'B': matrix_b[0:,j*split:j*split+split].tolist(),\n",
    "#                     'index': [i,j],\n",
    "#                     'op':'*'\n",
    "#                 })\n",
    "#             })\n",
    "#\n",
    "#             # sqs.send_message(\n",
    "#             #         QueueUrl=work_queue_url,\n",
    "#             #         MessageBody=messages[0]['MessageBody']\n",
    "#             # )\n",
    "#\n",
    "#             print(\"Messages 1\", messages)\n",
    "#\n",
    "#             id=0\n",
    "#             messages=[]\n",
    "#             msg += 1\n",
    "#             z = int(msg / nbr_msg * 25)\n",
    "#             #print progress bar\n",
    "#             sys.stdout.write('\\r')\n",
    "#             sys.stdout.write(\"[%-25s] %d%%\" % ('=' * z, 4 * z))\n",
    "#             sys.stdout.flush()\n",
    "#\n",
    "#         if rest>0:\n",
    "#\n",
    "#             messages.append({\n",
    "#                 'Id':str(int(len(matrix_a)/split)),\n",
    "#                 'MessageBody':str({\n",
    "#                     'A': matrix_a[i*split:i*split+split].tolist(),\n",
    "#                     'B': matrix_b[0:,lenght-rest:lenght].tolist(),\n",
    "#                     'index': [i,lenght//split],\n",
    "#                     'op':'*'\n",
    "#                 })\n",
    "#             })\n",
    "#\n",
    "#             print(\"Messages rest 1\", messages)\n",
    "#             # sqs.send_message(\n",
    "#             #         QueueUrl=work_queue_url,\n",
    "#             #         MessageBody=messages[0]['MessageBody']\n",
    "#             # )\n",
    "#             id=0\n",
    "#             messages=[]\n",
    "#\n",
    "#     if rest>0:\n",
    "#\n",
    "#         for j in range(int(len(matrix_b)/split)):\n",
    "#\n",
    "#             messages.append({\n",
    "#                 'Id':str(j),\n",
    "#                 'MessageBody':str({\n",
    "#                     'A': matrix_a[lenght-rest:lenght].tolist(),\n",
    "#                     'B': matrix_b[0:,j*split:j*split+split].tolist(),\n",
    "#                     'index': [lenght//split,j],\n",
    "#                     'op':'*'\n",
    "#                 })\n",
    "#             })\n",
    "#\n",
    "#             # sqs.send_message(\n",
    "#             #         QueueUrl=work_queue_url,\n",
    "#             #         MessageBody=messages[0]['MessageBody']\n",
    "#             # )\n",
    "#             print(\"Messages rest 2\", messages)\n",
    "#             id=0\n",
    "#             messages=[]\n",
    "#\n",
    "#         if rest>0:\n",
    "#\n",
    "#             messages.append({\n",
    "#                 'Id':str(int(len(matrix_a)/split)),\n",
    "#                 'MessageBody':str({\n",
    "#                     'A': matrix_a[lenght-rest:lenght].tolist(),\n",
    "#                     'B': matrix_b[0:,lenght-rest:lenght].tolist(),\n",
    "#                     'index': [lenght//split,lenght//split],\n",
    "#                     'op':'*'\n",
    "#                 })\n",
    "#             })\n",
    "#\n",
    "#             print(\"Messages rest 3\", messages)\n",
    "#\n",
    "#             # sqs.send_message(\n",
    "#             #         QueueUrl=work_queue_url,\n",
    "#             #         MessageBody=messages[0]['MessageBody']\n",
    "#             # )\n",
    "#             id=0\n",
    "#             messages=[]\n",
    "#\n",
    "#     return matrix_a,matrix_b,split,rest\n",
    "#\n",
    "#\n",
    "# # In[54]:\n",
    "#\n",
    "#\n",
    "# def receive_mul(proof,start):\n",
    "#     \"\"\"\n",
    "#     Receive the results from the workers\n",
    "#     :param proof: the proof of work (return [matrix_a,matrix_b,split,rest] of the send_mul function)\n",
    "#     :param start: the time when the work was started\n",
    "#     :return: the result\n",
    "#     \"\"\"\n",
    "#     result = np.zeros(proof[0].shape,dtype=np.int64) #create the result matrix\n",
    "#\n",
    "#     nbr_msg=0\n",
    "#     msg=0\n",
    "#     if proof[3]>0:\n",
    "#         nbr_msg+=(len(proof[0])//proof[2]+1)**2\n",
    "#     else:\n",
    "#         nbr_msg+=(len(proof[0])//proof[2])**2\n",
    "#\n",
    "#     print(\"\\nRECEIVING\")\n",
    "#\n",
    "#     while msg<nbr_msg:\n",
    "#         # Receive message from SQS queue\n",
    "#         response = queue.receive_messages(\n",
    "#                 QueueUrl=results_queue_url,\n",
    "#                 AttributeNames=['All'],\n",
    "#                 MaxNumberOfMessages=10,\n",
    "#                 VisibilityTimeout=30,\n",
    "#                 WaitTimeSeconds=0\n",
    "#             )\n",
    "#\n",
    "#         if len(response)>0:\n",
    "#             for resp in response:\n",
    "#                 dict =eval(resp.body)\n",
    "#\n",
    "#                 result[dict[\"index\"][0]*proof[2]:dict[\"index\"][0]*proof[2]+len(dict['value']),dict[\"index\"][1]*proof[2]:dict[\"index\"][1]*proof[2]+len(dict['value'][0])]=dict['value']\n",
    "#\n",
    "#                 sqs.delete_message(\n",
    "#                         QueueUrl=results_queue_url,\n",
    "#                         ReceiptHandle=resp.receipt_handle\n",
    "#                     )\n",
    "#                 msg+=1\n",
    "#                 z=int(msg/nbr_msg*25)\n",
    "#                 #print progress bar\n",
    "#                 sys.stdout.write('\\r')\n",
    "#                 sys.stdout.write(\"[%-25s] %d%%\" % ('=' * z, 4 * z))\n",
    "#                 sys.stdout.flush()\n",
    "#\n",
    "#     print(\"\\n****** RESULTS ******\")\n",
    "#     compute_time = time.time() - start\n",
    "#     print(\"TIME : \", compute_time)\n",
    "#\n",
    "#     #Verify the result\n",
    "#     if result.tolist() == np.dot(proof[0],proof[1]).tolist():\n",
    "#         print(\"VERIFICATION : Okay\")\n",
    "#     else:\n",
    "#         print(\"VERIFICATION : Not Okay\")\n",
    "#\n",
    "#     calc_cost(compute_time,len(get_ip_worker()),nbr_msg)\n",
    "#\n",
    "#     #write matrix to file\n",
    "#     with open('Mul_result.txt', 'w') as f:\n",
    "#         for item in result.tolist():\n",
    "#             f.write(\"%s \" % item)\n",
    "#\n",
    "#     print(\"RESULT SAVED TO FILE\")\n",
    "#     print(\"****** RESULTS ******\")\n",
    "#\n",
    "#     return result"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Terminating i-042276f6fa0ee39a8\n",
      "Terminating i-00f0ed952f24e950d\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'QueueUrls'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Input \u001B[0;32mIn [6]\u001B[0m, in \u001B[0;36m<cell line: 308>\u001B[0;34m()\u001B[0m\n\u001B[1;32m    305\u001B[0m         instance\u001B[38;5;241m.\u001B[39mterminate()\n\u001B[1;32m    307\u001B[0m terminate_instances()\n\u001B[0;32m--> 308\u001B[0m \u001B[43mmlbd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdelete_queues\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmlbd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msqs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Library/CloudStorage/OneDrive-CranfieldUniversity/Documents/Cranfield/CloudComputing/Cloud/MLBD.py:315\u001B[0m, in \u001B[0;36mMLBDApp.delete_queues\u001B[0;34m(self, sqs)\u001B[0m\n\u001B[1;32m    311\u001B[0m client \u001B[38;5;241m=\u001B[39m boto3\u001B[38;5;241m.\u001B[39mclient(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msqs\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m    312\u001B[0m response \u001B[38;5;241m=\u001B[39m client\u001B[38;5;241m.\u001B[39mlist_queues(\n\u001B[1;32m    313\u001B[0m     MaxResults\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m123\u001B[39m)\n\u001B[0;32m--> 315\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m queue \u001B[38;5;129;01min\u001B[39;00m \u001B[43mresponse\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mQueueUrls\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m:\n\u001B[1;32m    316\u001B[0m     client\u001B[38;5;241m.\u001B[39mdelete_queue(QueueUrl\u001B[38;5;241m=\u001B[39mqueue)\n\u001B[1;32m    317\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mqueue\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m deleted!\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[0;31mKeyError\u001B[0m: 'QueueUrls'"
     ]
    }
   ],
   "source": [
    "# INSTANCE_SIZE = 1\n",
    "# client = boto3.client('ec2', region_name='us-east-1')\n",
    "# # Create SQS client\n",
    "# sqs = boto3.resource('sqs')\n",
    "#\n",
    "# def get_default_security_group(client, key_name):\n",
    "#     #extract key_name attribute from the security groups returned\n",
    "#     response = [group[key_name] for group in client.describe_security_groups()['SecurityGroups'] if group['GroupName'] == 'default']\n",
    "#\n",
    "#     return response\n",
    "#\n",
    "# def get_key_pairs(client, removeExisting=False):\n",
    "#     if removeExisting:\n",
    "#         client.delete_key_pair(KeyName='airscholar-key')\n",
    "#\n",
    "#     keypairs = client.describe_key_pairs()['KeyPairs']\n",
    "#     keypair = list(filter(lambda x: x['KeyName'] == 'airscholar-key', keypairs))\n",
    "#\n",
    "#     if not keypair:\n",
    "#         keypair = client.create_key_pair(KeyName='airscholar-key')\n",
    "#         f = io.StringIO(keypair['KeyMaterial'])\n",
    "#         data = f.read()\n",
    "#         file = open('labsuser.pem', 'w')\n",
    "#         file.write(data)\n",
    "#         file.close()\n",
    "#     else:\n",
    "#         keypair = keypair[0]\n",
    "#\n",
    "#     return keypair\n",
    "#\n",
    "# def launch_new_instance(client, keypair, count):\n",
    "#     response = client.run_instances(\n",
    "#         ImageId='ami-05723c3b9cf4bf4ff',\n",
    "#         InstanceType='t2.micro',\n",
    "#         KeyName=keypair,\n",
    "#         MaxCount=count,\n",
    "#         MinCount=count,\n",
    "#         Monitoring={\n",
    "#             'Enabled': True\n",
    "#         },\n",
    "#         SecurityGroupIds= get_default_security_group(client, key_name='GroupId')\n",
    "#     )\n",
    "#     ec2_inst_ids = [res[\"InstanceId\"] for res in response]\n",
    "#     waiter = client.get_waiter('instance_running')\n",
    "#     waiter.wait(InstanceIds=[ec2_inst_ids])\n",
    "#     return ec2_inst_ids\n",
    "#\n",
    "# def prepare_instances(client, keypair, count):\n",
    "#     ec2 = boto3.resource('ec2')\n",
    "#     ec2_inst_ids = []\n",
    "#\n",
    "#     deployed_count = 0\n",
    "#     for instance in ec2.instances.all():\n",
    "#         deployed_count += 1\n",
    "#         client.start_instances(InstanceIds=[instance.id])\n",
    "#         ec2_inst_ids.append(instance.id)\n",
    "#\n",
    "#     if deployed_count < count:\n",
    "#         ec2_inst_ids.append(launch_new_instance(client, keypair, (count - deployed_count)))\n",
    "#\n",
    "#     if not ec2_inst_ids:\n",
    "#         ec2_inst_ids.append(launch_new_instance(client, keypair, count))\n",
    "#\n",
    "#     return ec2, ec2_inst_ids\n",
    "#\n",
    "# def configure_ssh():\n",
    "#     sshs = []\n",
    "#     for count in range(0, INSTANCE_SIZE):\n",
    "#         ssh = paramiko.SSHClient()\n",
    "#         ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())\n",
    "#         sshs.append(ssh)\n",
    "#     return sshs\n",
    "#\n",
    "# def ssh_connect_with_retry(ssh, ip_address, retries):\n",
    "#     if retries > 3:\n",
    "#         return False\n",
    "#     f = open('labsuser.pem', 'r')\n",
    "#     privkey = paramiko.RSAKey.from_private_key(f)\n",
    "#     # print(privkey)\n",
    "#     interval = 5\n",
    "#     try:\n",
    "#         retries += 1\n",
    "#         print('SSH into the instance: {}'.format(ip_address))\n",
    "#         ssh.connect(hostname=ip_address,\n",
    "#                     username='ec2-user', pkey=privkey)\n",
    "#         return True\n",
    "#     except Exception as e:\n",
    "#         print(e)\n",
    "#         time.sleep(interval)\n",
    "#         print('Retrying SSH connection to {}'.format(ip_address))\n",
    "#         ssh_connect_with_retry(ssh, ip_address, retries)\n",
    "#\n",
    "# def ssh_disconnect(ssh):\n",
    "#         \"\"\"Close ssh connection.\"\"\"\n",
    "#         if ssh:\n",
    "#             ssh.close()\n",
    "#\n",
    "# def get_public_address(ec2, instance_id):\n",
    "#     # ec2 = boto3.resource('ec2', region_name='us-east-1')\n",
    "#     instance = ec2.Instance(id=instance_id)\n",
    "#     instance.wait_until_running()\n",
    "#     current_instance = list(ec2.instances.filter(InstanceIds=[instance_id]))\n",
    "#     ip_address = current_instance[0].public_ip_address\n",
    "#     return ip_address\n",
    "#\n",
    "# def get_queue(sqs, queue_name='queue'):\n",
    "#     # Get the queue. This returns an SQS.Queue instance\n",
    "#     # There is no queue, create a new SQS queue\n",
    "#     attributes = {\n",
    "#         'DelaySeconds': '0',\n",
    "#         'MessageRetentionPeriod': '86400',\n",
    "#         \"ReceiveMessageWaitTimeSeconds\": \"0\"\n",
    "#     }\n",
    "#\n",
    "#     for idx in range(INSTANCE_SIZE):\n",
    "#         sqs.create_queue(\n",
    "#             QueueName=f\"{queue_name}{idx}\",\n",
    "#             Attributes=attributes\n",
    "#         )\n",
    "#\n",
    "#         sqs.create_queue(\n",
    "#             QueueName=f'result-queue-{idx}',\n",
    "#             Attributes=attributes\n",
    "#         )\n",
    "#\n",
    "# def send_message_to_queue(sqs, queue_name, message):\n",
    "#     queue = sqs.get_queue_by_name(QueueName=queue_name)\n",
    "#     # Send message to SQS queue\n",
    "#     response = queue.send_messages(\n",
    "#         Entries=message\n",
    "#     )\n",
    "#     # print(response)\n",
    "#     return response\n",
    "#\n",
    "# def install_required_packages(ssh):\n",
    "#     stdin, stdout, stderr = ssh.exec_command(\"sudo yum install pip -y && sudo pip install numpy boto3\")\n",
    "#     return stdout, stderr\n",
    "#\n",
    "# def initialise_instances(client):\n",
    "#     sshs = configure_ssh()\n",
    "#     keypair = get_key_pairs(client, False)\n",
    "#     ec2, instances = prepare_instances(client, keypair['KeyName'], INSTANCE_SIZE)\n",
    "#     ip_addresses = [get_public_address(ec2, instance) for instance in instances]\n",
    "#     print(list(ip_addresses))\n",
    "#     for idx in range(0, len(sshs)):\n",
    "#         ssh = sshs[idx]\n",
    "#         ip_address = ip_addresses[idx]\n",
    "#         # connect to ssh\n",
    "#         print(f\"Conencting to Instance-{idx} with IP Address {ip_address}\")\n",
    "#         ssh_connect_with_retry(ssh, ip_address, 0)\n",
    "#         # install required python packages\n",
    "#         print(f\"Installing required packages for Instance-{idx} with IP Address {ip_address}\")\n",
    "#         stdout, stderr = install_required_packages(ssh)\n",
    "#         print(stdout.read().decode('utf-8'))\n",
    "#         print(stderr.read().decode('utf-8'))\n",
    "#\n",
    "#         #configure aws access to the instance\n",
    "#         print(f\"Configuring Instance -{idx} with IP Address {ip_address} for remote access\")\n",
    "#         configure_aws_access_for_ssh(ssh, ip_address)\n",
    "#\n",
    "#         #upload worker file to the instance\n",
    "#         scp = SCPClient(ssh.get_transport())\n",
    "#         bulk_upload(scp, fetch_local_files('./worker'), '~', ip_address)\n",
    "#\n",
    "#         # start worker on the instance\n",
    "#         print(f\"Starting worker {idx}\")\n",
    "#         stdin, stdout, stderr = ssh.exec_command(f'python ./worker.py {idx}')\n",
    "#         # # print(stdout.read().decode('utf-8'))\n",
    "#         # # print(stderr.read().decode('utf-8'))\n",
    "#\n",
    "# def get_messages_from_queue(instance_size, queue, message_size=10):\n",
    "#     messages = []\n",
    "#     sqs = boto3.resource('sqs')\n",
    "#     queue = sqs.get_queue_by_name(QueueName=queue)\n",
    "#\n",
    "#     for message in queue.receive_messages(MaxNumberOfMessages=message_size, MessageAttributeNames=['All'], WaitTimeSeconds=0):\n",
    "#         messages.append(literal_eval(message.body))\n",
    "#         message.delete()\n",
    "#     return messages\n",
    "#\n",
    "# def split_row(array, nrows, ncols):\n",
    "#     \"\"\"\n",
    "#     Return an array of shape (n, nrows, ncols) where\n",
    "#     n * nrows * ncols = arr.size\n",
    "#\n",
    "#     If arr is a 2D array, the returned array should look like n subblocks with\n",
    "#     each subblock preserving the \"physical\" layout of arr.\n",
    "#     \"\"\"\n",
    "#     h, w = array.shape\n",
    "#     assert h % nrows == 0, f\"{h} rows is not evenly divisible by {nrows}\"\n",
    "#     assert w % ncols == 0, f\"{w} cols is not evenly divisible by {ncols}\"\n",
    "#     return (array.reshape(h//nrows, nrows, -1, ncols)\n",
    "#                .swapaxes(1,2)\n",
    "#                .reshape(-1, nrows, ncols))\n",
    "#\n",
    "# def split_col(array, nrows, ncols):\n",
    "#     \"\"\"Split a matrix into sub-matrices.\"\"\"\n",
    "#     r, h = array.shape\n",
    "#     return [np.vsplit(i, 5) for i in np.hsplit(arr1, r)]\n",
    "#\n",
    "# def generate_array(nrows, ncols):\n",
    "#     arr = np.random.randint(5, size=(nrows, ncols))\n",
    "#     # # print('arr 1:\\n', arr)\n",
    "#     # arr = split_row(arr, 1, split_size)\n",
    "#     arr1 = np.random.randint(5, size=(nrows, ncols))\n",
    "#     # print('arr 2:\\n', arr1)\n",
    "#     # arr1 = split_col(arr1, 1, split_size)\n",
    "#\n",
    "#     return arr, arr1\n",
    "#\n",
    "# def upload_file_to_s3(file_name, bucket, object_name=None):\n",
    "#     \"\"\"Upload a file to an S3 bucket\n",
    "#\n",
    "#     :param file_name: File to upload\n",
    "#     :param bucket: Bucket to upload to\n",
    "#     :param object_name: S3 object name. If not specified then file_name is used\n",
    "#     :return: True if file was uploaded, else False\n",
    "#     \"\"\"\n",
    "#\n",
    "#     # If S3 object_name was not specified, use file_name\n",
    "#     if object_name is None:\n",
    "#         object_name = os.path.basename(file_name)\n",
    "#\n",
    "#     # Upload the file\n",
    "#     s3_client = boto3.client('s3')\n",
    "#     try:\n",
    "#         response = s3_client.upload_file(file_name, bucket, object_name)\n",
    "#     except:\n",
    "#         # logging.error(e)\n",
    "#         return False\n",
    "#     return True\n",
    "#\n",
    "# def bulk_upload(scp, filepaths: list[str], remote_path, host):\n",
    "#         \"\"\"\n",
    "#         Upload multiple files to a remote directory.\n",
    "#\n",
    "#         :param List[str] filepaths: List of local files to be uploaded.\n",
    "#         \"\"\"\n",
    "#         try:\n",
    "#             scp.put(\n",
    "#                 filepaths,\n",
    "#                 remote_path=remote_path,\n",
    "#                 recursive=True\n",
    "#             )\n",
    "#             print(f\"Finished uploading {len(filepaths)} files to {remote_path} on {host}\")\n",
    "#         except SCPException as e:\n",
    "#             print(f\"SCPException during bulk upload: {e}\")\n",
    "#         except Exception as e:\n",
    "#             print(f\"Unexpected exception during bulk upload: {e}\")\n",
    "#\n",
    "# def configure_aws_access_for_ssh(ssh, ip_address):\n",
    "#     \"\"\"\n",
    "#     This function extracts the AWS configuration you have locally and push to the server\n",
    "#     :param ssh:ssh object\n",
    "#     :return:\n",
    "#     \"\"\"\n",
    "#     output = subprocess.getoutput(\"cat ~/.aws/credentials\")\n",
    "#     ssh.exec_command(f'mkdir ~/.aws && touch ~/.aws/credentials')\n",
    "#     ssh.exec_command(f\"echo '{output}' > ~/.aws/credentials\")\n",
    "#     print(f'SSH AWS configuration done for {ip_address}')\n",
    "#\n",
    "# def matrix_dot_product(matrix_a, matrix_b):\n",
    "#     start_time = datetime.datetime.now()\n",
    "#     result = []\n",
    "#     for i in range(len(matrix_a)):\n",
    "#         row = []\n",
    "#         for j in range(len(matrix_b[0])):\n",
    "#             sum = 0\n",
    "#             for k in range(len(matrix_b)):\n",
    "#                 sum += matrix_a[i][k] * matrix_b[k][j]\n",
    "#             row.append(sum)\n",
    "#         result.append(row)\n",
    "#     print('Computation time', datetime.datetime.now() - start_time)\n",
    "#\n",
    "#     return result\n",
    "#\n",
    "# def matrix_add(matrix_1, matrix_2):\n",
    "#     start_time = datetime.datetime.now()\n",
    "#     result = []\n",
    "#     for idx_row in range(0, len(matrix_1)):\n",
    "#         row = matrix_1[idx_row]\n",
    "#         row1 = matrix_2[idx_row]\n",
    "#         cols = []\n",
    "#         for idx_col in range(0, len(row)):\n",
    "#             cols.append(row[idx_col] + row1[idx_col])\n",
    "#         result.append(cols)\n",
    "#     print('Computation time', datetime.datetime.now() - start_time)\n",
    "#     return result\n",
    "#\n",
    "# def delete_queues(sqs):\n",
    "#     #get all the queues\n",
    "#     client = boto3.client('sqs')\n",
    "#     response = client.list_queues(\n",
    "#     MaxResults=123)\n",
    "#\n",
    "#     for queue in response['QueueUrls']:\n",
    "#         client.delete_queue(QueueUrl= queue)\n",
    "#         print(f'{queue} deleted!')\n",
    "#\n",
    "# def terminate_instances():\n",
    "#     ec2 = boto3.resource('ec2')\n",
    "#     for instance in ec2.instances.all():\n",
    "#         # terminate all instances\n",
    "#         print(f'Terminating {instance.id}')\n",
    "#         instance.terminate()\n",
    "#\n",
    "# terminate_instances()\n",
    "# mlbd.delete_queues(mlbd.sqs)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5bc0a3eb-3bc7-4d62-b967-4131688e16b2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ClientError",
     "evalue": "An error occurred (ExpiredToken) when calling the CreateQueue operation: The security token included in the request is expired",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mClientError\u001B[0m                               Traceback (most recent call last)",
      "Input \u001B[0;32mIn [5]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mmlbd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_queue\u001B[49m\u001B[43m(\u001B[49m\u001B[43msqs\u001B[49m\u001B[43m)\u001B[49m\n",
      "Input \u001B[0;32mIn [3]\u001B[0m, in \u001B[0;36mMLBDApp.get_queue\u001B[0;34m(self, sqs, queue_name)\u001B[0m\n\u001B[1;32m    109\u001B[0m attributes \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m    110\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mDelaySeconds\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m0\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m    111\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mMessageRetentionPeriod\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m86400\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m    112\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mReceiveMessageWaitTimeSeconds\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m0\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    113\u001B[0m }\n\u001B[1;32m    115\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(INSTANCE_SIZE):\n\u001B[0;32m--> 116\u001B[0m     \u001B[43msqs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcreate_queue\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    117\u001B[0m \u001B[43m        \u001B[49m\u001B[43mQueueName\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43mf\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mqueue_name\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43midx\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    118\u001B[0m \u001B[43m        \u001B[49m\u001B[43mAttributes\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattributes\u001B[49m\n\u001B[1;32m    119\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    121\u001B[0m     sqs\u001B[38;5;241m.\u001B[39mcreate_queue(\n\u001B[1;32m    122\u001B[0m         QueueName\u001B[38;5;241m=\u001B[39m\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mresult-queue-\u001B[39m\u001B[38;5;132;01m{\u001B[39;00midx\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m    123\u001B[0m         Attributes\u001B[38;5;241m=\u001B[39mattributes\n\u001B[1;32m    124\u001B[0m     )\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.9/site-packages/boto3/resources/factory.py:580\u001B[0m, in \u001B[0;36mResourceFactory._create_action.<locals>.do_action\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    579\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdo_action\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m--> 580\u001B[0m     response \u001B[38;5;241m=\u001B[39m \u001B[43maction\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    582\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mload\u001B[39m\u001B[38;5;124m'\u001B[39m):\n\u001B[1;32m    583\u001B[0m         \u001B[38;5;66;03m# Clear cached data. It will be reloaded the next\u001B[39;00m\n\u001B[1;32m    584\u001B[0m         \u001B[38;5;66;03m# time that an attribute is accessed.\u001B[39;00m\n\u001B[1;32m    585\u001B[0m         \u001B[38;5;66;03m# TODO: Make this configurable in the future?\u001B[39;00m\n\u001B[1;32m    586\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmeta\u001B[38;5;241m.\u001B[39mdata \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.9/site-packages/boto3/resources/action.py:88\u001B[0m, in \u001B[0;36mServiceAction.__call__\u001B[0;34m(self, parent, *args, **kwargs)\u001B[0m\n\u001B[1;32m     79\u001B[0m params\u001B[38;5;241m.\u001B[39mupdate(kwargs)\n\u001B[1;32m     81\u001B[0m logger\u001B[38;5;241m.\u001B[39mdebug(\n\u001B[1;32m     82\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mCalling \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m:\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m with \u001B[39m\u001B[38;5;132;01m%r\u001B[39;00m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m     83\u001B[0m     parent\u001B[38;5;241m.\u001B[39mmeta\u001B[38;5;241m.\u001B[39mservice_name,\n\u001B[1;32m     84\u001B[0m     operation_name,\n\u001B[1;32m     85\u001B[0m     params,\n\u001B[1;32m     86\u001B[0m )\n\u001B[0;32m---> 88\u001B[0m response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mgetattr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mparent\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmeta\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mclient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moperation_name\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mparams\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     90\u001B[0m logger\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mResponse: \u001B[39m\u001B[38;5;132;01m%r\u001B[39;00m\u001B[38;5;124m'\u001B[39m, response)\n\u001B[1;32m     92\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_response_handler(parent, params, response)\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.9/site-packages/botocore/client.py:515\u001B[0m, in \u001B[0;36mClientCreator._create_api_method.<locals>._api_call\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    511\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\n\u001B[1;32m    512\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpy_operation_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m() only accepts keyword arguments.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    513\u001B[0m     )\n\u001B[1;32m    514\u001B[0m \u001B[38;5;66;03m# The \"self\" in this scope is referring to the BaseClient.\u001B[39;00m\n\u001B[0;32m--> 515\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_make_api_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43moperation_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.9/site-packages/botocore/client.py:934\u001B[0m, in \u001B[0;36mBaseClient._make_api_call\u001B[0;34m(self, operation_name, api_params)\u001B[0m\n\u001B[1;32m    932\u001B[0m     error_code \u001B[38;5;241m=\u001B[39m parsed_response\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mError\u001B[39m\u001B[38;5;124m\"\u001B[39m, {})\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCode\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    933\u001B[0m     error_class \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexceptions\u001B[38;5;241m.\u001B[39mfrom_code(error_code)\n\u001B[0;32m--> 934\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m error_class(parsed_response, operation_name)\n\u001B[1;32m    935\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    936\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m parsed_response\n",
      "\u001B[0;31mClientError\u001B[0m: An error occurred (ExpiredToken) when calling the CreateQueue operation: The security token included in the request is expired"
     ]
    }
   ],
   "source": [
    "mlbd.get_queue(sqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "ename": "ClientError",
     "evalue": "An error occurred (RequestExpired) when calling the DescribeKeyPairs operation: Request has expired.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mClientError\u001B[0m                               Traceback (most recent call last)",
      "Input \u001B[0;32mIn [6]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mmlbd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minitialise_instances\u001B[49m\u001B[43m(\u001B[49m\u001B[43mclient\u001B[49m\u001B[43m)\u001B[49m\n",
      "Input \u001B[0;32mIn [3]\u001B[0m, in \u001B[0;36mMLBDApp.initialise_instances\u001B[0;34m(self, client)\u001B[0m\n\u001B[1;32m    139\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21minitialise_instances\u001B[39m(\u001B[38;5;28mself\u001B[39m, client):\n\u001B[1;32m    140\u001B[0m     sshs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfigure_ssh()\n\u001B[0;32m--> 141\u001B[0m     keypair \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_key_pairs\u001B[49m\u001B[43m(\u001B[49m\u001B[43mclient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m    142\u001B[0m     ec2, instances \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprepare_instances(client, keypair[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mKeyName\u001B[39m\u001B[38;5;124m'\u001B[39m], INSTANCE_SIZE)\n\u001B[1;32m    143\u001B[0m     ip_addresses \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_public_address(ec2, instance) \u001B[38;5;28;01mfor\u001B[39;00m instance \u001B[38;5;129;01min\u001B[39;00m instances]\n",
      "Input \u001B[0;32mIn [3]\u001B[0m, in \u001B[0;36mMLBDApp.get_key_pairs\u001B[0;34m(self, client, removeExisting)\u001B[0m\n\u001B[1;32m     13\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m removeExisting:\n\u001B[1;32m     14\u001B[0m     client\u001B[38;5;241m.\u001B[39mdelete_key_pair(KeyName\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mairscholar-key\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m---> 16\u001B[0m keypairs \u001B[38;5;241m=\u001B[39m \u001B[43mclient\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdescribe_key_pairs\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mKeyPairs\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[1;32m     17\u001B[0m keypair \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(\u001B[38;5;28mfilter\u001B[39m(\u001B[38;5;28;01mlambda\u001B[39;00m x: x[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mKeyName\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mairscholar-key\u001B[39m\u001B[38;5;124m'\u001B[39m, keypairs))\n\u001B[1;32m     19\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m keypair:\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.9/site-packages/botocore/client.py:515\u001B[0m, in \u001B[0;36mClientCreator._create_api_method.<locals>._api_call\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    511\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\n\u001B[1;32m    512\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpy_operation_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m() only accepts keyword arguments.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    513\u001B[0m     )\n\u001B[1;32m    514\u001B[0m \u001B[38;5;66;03m# The \"self\" in this scope is referring to the BaseClient.\u001B[39;00m\n\u001B[0;32m--> 515\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_make_api_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43moperation_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.9/site-packages/botocore/client.py:934\u001B[0m, in \u001B[0;36mBaseClient._make_api_call\u001B[0;34m(self, operation_name, api_params)\u001B[0m\n\u001B[1;32m    932\u001B[0m     error_code \u001B[38;5;241m=\u001B[39m parsed_response\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mError\u001B[39m\u001B[38;5;124m\"\u001B[39m, {})\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCode\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    933\u001B[0m     error_class \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexceptions\u001B[38;5;241m.\u001B[39mfrom_code(error_code)\n\u001B[0;32m--> 934\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m error_class(parsed_response, operation_name)\n\u001B[1;32m    935\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    936\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m parsed_response\n",
      "\u001B[0;31mClientError\u001B[0m: An error occurred (RequestExpired) when calling the DescribeKeyPairs operation: Request has expired."
     ]
    }
   ],
   "source": [
    "mlbd.initialise_instances(client)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### ADDITION"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "33cd3d74-e2a8-4959-817f-58c893854021",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "   # [print(idx, dt) for idx in range(min(dt), max(dt)+1)]\n",
    "        # result = []\n",
    "        # for i in range(min(dt), max(dt)+1):\n",
    "        #     row = []\n",
    "        #     start = min(dt)\n",
    "        #     end = max(dt)+1\n",
    "        #     for j in range(start, end):\n",
    "        #         idx = []\n",
    "        #         row_sum = sum(arr[i]*arr1.T[j])\n",
    "        #         row.append(row_sum)\n",
    "        #     print(row)\n",
    "        #     # print(id, '=>', start, end)\n",
    "        # result.append(row)\n",
    "# np.array(result)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "outputs": [],
   "source": [
    "# task1(15, 5, 'addition')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "def split_and_compute_dot_product(matrix_a, matrix_b, chunk_size):\n",
    "    \"\"\"\n",
    "    Splits two huge matrices into smaller chunks and computes the dot product for each pair of chunks without using any libraries.\n",
    "\n",
    "    Parameters:\n",
    "    - matrix_a (list): The first matrix to split and compute the dot product for.\n",
    "    - matrix_b (list): The second matrix to split and compute the dot product for.\n",
    "    - chunk_size (int): The size of each chunk.\n",
    "\n",
    "    Returns:\n",
    "    - dot_products (list): A list of dot products for each pair of chunks.\n",
    "    \"\"\"\n",
    "    # Split the matrices into chunks\n",
    "    chunks_a = [matrix_a[i:i+chunk_size] for i in range(0, len(matrix_a), chunk_size)]\n",
    "    chunks_b = [matrix_b[i:i+chunk_size] for i in range(0, len(matrix_b), chunk_size)]\n",
    "\n",
    "    # Initialize a list to store the dot products\n",
    "    dot_products = []\n",
    "\n",
    "    # Iterate over the chunks and compute the dot product for each pair of chunks\n",
    "    for chunk_a, chunk_b in zip(chunks_a, chunks_b):\n",
    "        print(chunk_a, chunk_b)\n",
    "        dot_product = [[0 for j in range(len(chunk_a))] for i in range(len(chunk_b[0]))]\n",
    "        print(dot_product)\n",
    "        for i in range(len(chunk_b)):\n",
    "            for j in range(len(chunk_a[0])):\n",
    "                for k in range(len(chunk_b[0])):\n",
    "                    dot_product[i][j] += chunk_b[i][k] * chunk_a[k][j]\n",
    "\n",
    "        dot_products.append(dot_product)\n",
    "\n",
    "    return dot_products"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3 1 3 3]\n",
      " [1 1 2 4]] [[4 0 0 4]\n",
      " [1 1 0 4]]\n",
      "[[0, 0], [0, 0], [0, 0], [0, 0]]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 2 is out of bounds for axis 0 with size 2",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "Input \u001B[0;32mIn [26]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43msplit_and_compute_dot_product\u001B[49m\u001B[43m(\u001B[49m\u001B[43marr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43marr1\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Input \u001B[0;32mIn [25]\u001B[0m, in \u001B[0;36msplit_and_compute_dot_product\u001B[0;34m(matrix_a, matrix_b, chunk_size)\u001B[0m\n\u001B[1;32m     26\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m j \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(chunk_a[\u001B[38;5;241m0\u001B[39m])):\n\u001B[1;32m     27\u001B[0m             \u001B[38;5;28;01mfor\u001B[39;00m k \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(chunk_b[\u001B[38;5;241m0\u001B[39m])):\n\u001B[0;32m---> 28\u001B[0m                 dot_product[i][j] \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m chunk_b[i][k] \u001B[38;5;241m*\u001B[39m \u001B[43mchunk_a\u001B[49m\u001B[43m[\u001B[49m\u001B[43mk\u001B[49m\u001B[43m]\u001B[49m[j]\n\u001B[1;32m     30\u001B[0m     dot_products\u001B[38;5;241m.\u001B[39mappend(dot_product)\n\u001B[1;32m     32\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m dot_products\n",
      "\u001B[0;31mIndexError\u001B[0m: index 2 is out of bounds for axis 0 with size 2"
     ]
    }
   ],
   "source": [
    "split_and_compute_dot_product(arr, arr1, 2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[2, 4, 0, 3, 3, 3, 0, 3, 4, 4],\n       [0, 1, 2, 0, 3, 0, 1, 0, 3, 1],\n       [3, 4, 1, 1, 1, 0, 2, 1, 1, 0],\n       [0, 4, 2, 3, 4, 0, 0, 4, 1, 4],\n       [0, 2, 0, 3, 1, 0, 3, 0, 0, 2],\n       [1, 1, 1, 4, 2, 3, 4, 2, 4, 3],\n       [4, 2, 4, 3, 0, 1, 2, 4, 3, 0],\n       [1, 2, 3, 4, 1, 4, 2, 1, 3, 3],\n       [0, 4, 3, 1, 3, 2, 2, 2, 2, 1],\n       [3, 4, 1, 0, 3, 3, 2, 1, 1, 0]])"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "array_size = 4\n",
    "chunk_size = 2\n",
    "operation = 'multiply'\n",
    "# print(f'Generating {array_size}x{array_size} matrix')\n",
    "arr, arr1 = generate_array(array_size,array_size)\n",
    "# print(f'Splitting {array_size}x{array_size} matrix into {chunk_size}x{chunk_size}')\n",
    "# s_arr = split_row(arr, chunk_size, chunk_size)\n",
    "# s_arr1 = split_row(arr1.T, chunk_size, chunk_size)\n",
    "# print(arr1.T, '\\n')\n",
    "# print(s_arr1)\n",
    "#manual matrix addition\n",
    "# print(f'Computing manual addition of {array_size}x{array_size} matrix')\n",
    "# res1 = np.array(matrix_dot_product(arr, arr1))\n",
    "# print(res1)\n",
    "# # print(f\"\\nComputing distribution {operation} operation for {array_size}x{array_size}\")\n",
    "# compute_matrix_operation(operation, s_arr, s_arr1)\n",
    "# #wait for 15 seconds\n",
    "# print('Wait 60 seconds before computing result')\n",
    "# time.sleep(60)\n",
    "# #merge all the queue results\n",
    "# print(f\"\\nMerging computation results\")\n",
    "# res2 = merge_queue_result(s_arr, array_size, chunk_size)\n",
    "# print(f\"\\nVerifying computation results\")\n",
    "# print(np.array(res1 == res2))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eb35587b-cee3-455a-a86d-1b4c6b875653",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create instance\n",
    "#configure instance\n",
    "#create matrix\n",
    "#split matrix\n",
    "#send matrix to the queue\n",
    "#read matrix from the queue on the instance created\n",
    "#compute matrix\n",
    "#send result to base\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "d149a3f8-392e-4080-8ecc-d00c56714648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[main 356fbbd] Updated Addition Workflow\r\n",
      " 1 file changed, 9 insertions(+), 10 deletions(-)\r\n",
      "Enumerating objects: 5, done.\r\n",
      "Counting objects: 100% (5/5), done.\r\n",
      "Delta compression using up to 8 threads\r\n",
      "Compressing objects: 100% (3/3), done.\r\n",
      "Writing objects: 100% (3/3), 469 bytes | 469.00 KiB/s, done.\r\n",
      "Total 3 (delta 2), reused 0 (delta 0), pack-reused 0\r\n",
      "remote: Resolving deltas: 100% (2/2), completed with 2 local objects.\u001B[K\r\n",
      "To https://github.com/airscholar/MLCloudComputing-python.git\r\n",
      "   2d62b4f..356fbbd  main -> main\r\n"
     ]
    }
   ],
   "source": [
    "!git add . && git commit -am \"Updated Addition Workflow\"\n",
    "!git push"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e9fc665d",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
